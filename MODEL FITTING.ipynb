{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaef2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('cleaned_loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743afce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>85994</td>\n",
       "      <td>50587</td>\n",
       "      <td>520</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>50432</td>\n",
       "      <td>124440</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>84208</td>\n",
       "      <td>129188</td>\n",
       "      <td>451</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>31713</td>\n",
       "      <td>44799</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.07</td>\n",
       "      <td>24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>20437</td>\n",
       "      <td>9139</td>\n",
       "      <td>633</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.51</td>\n",
       "      <td>48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
       "0   56   85994       50587          520              80               4   \n",
       "1   69   50432      124440          458              15               1   \n",
       "2   46   84208      129188          451              26               3   \n",
       "3   32   31713       44799          743               0               3   \n",
       "4   60   20437        9139          633               8               4   \n",
       "\n",
       "   InterestRate  LoanTerm  DTIRatio  Education  EmploymentType  MaritalStatus  \\\n",
       "0         15.23        36      0.44          0               0              0   \n",
       "1          4.81        60      0.68          2               0              0   \n",
       "2         21.17        24      0.31          2               3              0   \n",
       "3          7.07        24      0.23          1               0              1   \n",
       "4          6.51        48      0.73          0               3              0   \n",
       "\n",
       "   HasMortgage  HasDependents  LoanPurpose  HasCoSigner  Default  \n",
       "0            1              1            0            1        0  \n",
       "1            0              0            0            1        0  \n",
       "2            1              1            1            0        1  \n",
       "3            0              0            0            0        0  \n",
       "4            0              1            1            0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "588b11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('Default',axis=1)\n",
    "y=data['Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77343bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dd4e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest f1 score: 0.08708793803721544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest f1 score: {rf_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "gb_f1 = f1_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting f1 score: {gb_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ad5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost f1: 0.137427681352915\n"
     ]
    }
   ],
   "source": [
    "# Fit XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost f1: {xgb_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cd90d",
   "metadata": {},
   "source": [
    "# MODEL PERFORMANCE UNDER OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b22d122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 180524, number of negative: 180524\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 361048, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "                 Model  Accuracy  Precision  F1 Score    Recall\n",
      "0  Logistic Regression  0.665303   0.198286  0.300871  0.623390\n",
      "1        Decision Tree  0.814666   0.200471  0.201333  0.202203\n",
      "2        Random Forest  0.884903   0.511482  0.142899  0.083051\n",
      "3    Gradient Boosting  0.689740   0.224805  0.338938  0.688475\n",
      "4              XGBoost  0.716076   0.231586  0.338504  0.628814\n",
      "5             LightGBM  0.699217   0.229144  0.342564  0.678305\n",
      "6                  KNN  0.664480   0.134444  0.194292  0.350169\n",
      "7          Naive Bayes  0.660055   0.209156  0.321915  0.698475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def fit_and_evaluate_models_ros(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Perform random over-sampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Define models to train\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Initialize a DataFrame to store the results\n",
    "    metrics = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"F1 Score\", \"Recall\"])\n",
    "    \n",
    "    # Train each model and evaluate\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_ros, y_train_ros)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        metrics = metrics.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Recall\": recall\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage\n",
    "metrics_df_ros= fit_and_evaluate_models_ros(X, y)\n",
    "print(metrics_df_ros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc591434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.665303</td>\n",
       "      <td>0.198286</td>\n",
       "      <td>0.300871</td>\n",
       "      <td>0.623390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.814666</td>\n",
       "      <td>0.200471</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.202203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.884903</td>\n",
       "      <td>0.511482</td>\n",
       "      <td>0.142899</td>\n",
       "      <td>0.083051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.689740</td>\n",
       "      <td>0.224805</td>\n",
       "      <td>0.338938</td>\n",
       "      <td>0.688475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.716076</td>\n",
       "      <td>0.231586</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>0.628814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.699217</td>\n",
       "      <td>0.229144</td>\n",
       "      <td>0.342564</td>\n",
       "      <td>0.678305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.664480</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>0.194292</td>\n",
       "      <td>0.350169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.660055</td>\n",
       "      <td>0.209156</td>\n",
       "      <td>0.321915</td>\n",
       "      <td>0.698475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  F1 Score    Recall\n",
       "0  Logistic Regression  0.665303   0.198286  0.300871  0.623390\n",
       "1        Decision Tree  0.814666   0.200471  0.201333  0.202203\n",
       "2        Random Forest  0.884903   0.511482  0.142899  0.083051\n",
       "3    Gradient Boosting  0.689740   0.224805  0.338938  0.688475\n",
       "4              XGBoost  0.716076   0.231586  0.338504  0.628814\n",
       "5             LightGBM  0.699217   0.229144  0.342564  0.678305\n",
       "6                  KNN  0.664480   0.134444  0.194292  0.350169\n",
       "7          Naive Bayes  0.660055   0.209156  0.321915  0.698475"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16f05221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 23753, number of negative: 23753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1302\n",
      "[LightGBM] [Info] Number of data points in the train set: 47506, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "                 Model  Accuracy  Precision  F1 Score    Recall\n",
      "0  Logistic Regression  0.674094   0.211400  0.321041  0.666949\n",
      "1        Decision Tree  0.588075   0.154043  0.242647  0.571186\n",
      "2        Random Forest  0.683552   0.218429  0.330003  0.674576\n",
      "3    Gradient Boosting  0.684355   0.222011  0.336134  0.691695\n",
      "4              XGBoost  0.673389   0.211888  0.322172  0.671864\n",
      "5             LightGBM  0.686156   0.222673  0.336589  0.689153\n",
      "6                  KNN  0.544958   0.132477  0.211943  0.529661\n",
      "7          Naive Bayes  0.659174   0.208620  0.321245  0.698136\n"
     ]
    }
   ],
   "source": [
    "from  imblearn.under_sampling import RandomUnderSampler\n",
    "def fit_and_evaluate_models_rus(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Perform random over-sampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Define models to train\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Initialize a DataFrame to store the results\n",
    "    metrics = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"F1 Score\", \"Recall\"])\n",
    "    \n",
    "    # Train each model and evaluate\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_rus, y_train_rus)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        metrics = metrics.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Recall\": recall\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage\n",
    "metrics_rus_df = fit_and_evaluate_models_rus(X, y)\n",
    "print(metrics_rus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b197e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.674094</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.321041</td>\n",
       "      <td>0.666949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.588075</td>\n",
       "      <td>0.154043</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0.571186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.683552</td>\n",
       "      <td>0.218429</td>\n",
       "      <td>0.330003</td>\n",
       "      <td>0.674576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.684355</td>\n",
       "      <td>0.222011</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.691695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.673389</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.322172</td>\n",
       "      <td>0.671864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.686156</td>\n",
       "      <td>0.222673</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.689153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.544958</td>\n",
       "      <td>0.132477</td>\n",
       "      <td>0.211943</td>\n",
       "      <td>0.529661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.659174</td>\n",
       "      <td>0.208620</td>\n",
       "      <td>0.321245</td>\n",
       "      <td>0.698136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  F1 Score    Recall\n",
       "0  Logistic Regression  0.674094   0.211400  0.321041  0.666949\n",
       "1        Decision Tree  0.588075   0.154043  0.242647  0.571186\n",
       "2        Random Forest  0.683552   0.218429  0.330003  0.674576\n",
       "3    Gradient Boosting  0.684355   0.222011  0.336134  0.691695\n",
       "4              XGBoost  0.673389   0.211888  0.322172  0.671864\n",
       "5             LightGBM  0.686156   0.222673  0.336589  0.689153\n",
       "6                  KNN  0.544958   0.132477  0.211943  0.529661\n",
       "7          Naive Bayes  0.659174   0.208620  0.321245  0.698136"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "977a1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 180524, number of negative: 180524\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 361048, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "                 Model  Accuracy  Precision  F1 Score    Recall\n",
      "0  Logistic Regression  0.677736   0.212191  0.321096  0.659661\n",
      "1        Decision Tree  0.747758   0.178723  0.231659  0.329153\n",
      "2        Random Forest  0.832407   0.265148  0.259666  0.254407\n",
      "3    Gradient Boosting  0.845565   0.297864  0.270735  0.248136\n",
      "4              XGBoost  0.876248   0.391975  0.194289  0.129153\n",
      "5             LightGBM  0.859252   0.326695  0.252496  0.205763\n",
      "6                  KNN  0.626004   0.130955  0.196939  0.396949\n",
      "7          Naive Bayes  0.672606   0.208733  0.316826  0.657119\n"
     ]
    }
   ],
   "source": [
    "from  imblearn.over_sampling import SMOTENC \n",
    "def fit_and_evaluate_models_smt(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Perform random over-sampling\n",
    "    smt = SMOTENC(random_state=42,categorical_features=np.arange(9,16,1))\n",
    "    X_train_smt, y_train_smt = smt.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Define models to train\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Initialize a DataFrame to store the results\n",
    "    metrics = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"F1 Score\", \"Recall\"])\n",
    "    \n",
    "    # Train each model and evaluate\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_smt, y_train_smt)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        metrics = metrics.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Recall\": recall\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage\n",
    "metrics_smt_df = fit_and_evaluate_models_smt(X, y)\n",
    "print(metrics_smt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40beaed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.677736</td>\n",
       "      <td>0.212191</td>\n",
       "      <td>0.321096</td>\n",
       "      <td>0.659661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.747758</td>\n",
       "      <td>0.178723</td>\n",
       "      <td>0.231659</td>\n",
       "      <td>0.329153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.832407</td>\n",
       "      <td>0.265148</td>\n",
       "      <td>0.259666</td>\n",
       "      <td>0.254407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.845565</td>\n",
       "      <td>0.297864</td>\n",
       "      <td>0.270735</td>\n",
       "      <td>0.248136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.876248</td>\n",
       "      <td>0.391975</td>\n",
       "      <td>0.194289</td>\n",
       "      <td>0.129153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.859252</td>\n",
       "      <td>0.326695</td>\n",
       "      <td>0.252496</td>\n",
       "      <td>0.205763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.626004</td>\n",
       "      <td>0.130955</td>\n",
       "      <td>0.196939</td>\n",
       "      <td>0.396949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>0.208733</td>\n",
       "      <td>0.316826</td>\n",
       "      <td>0.657119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  F1 Score    Recall\n",
       "0  Logistic Regression  0.677736   0.212191  0.321096  0.659661\n",
       "1        Decision Tree  0.747758   0.178723  0.231659  0.329153\n",
       "2        Random Forest  0.832407   0.265148  0.259666  0.254407\n",
       "3    Gradient Boosting  0.845565   0.297864  0.270735  0.248136\n",
       "4              XGBoost  0.876248   0.391975  0.194289  0.129153\n",
       "5             LightGBM  0.859252   0.326695  0.252496  0.205763\n",
       "6                  KNN  0.626004   0.130955  0.196939  0.396949\n",
       "7          Naive Bayes  0.672606   0.208733  0.316826  0.657119"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_smt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "740413ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 100854, number of negative: 100853\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "[LightGBM] [Info] Number of positive: 100853, number of negative: 100854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 201707, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
      "[LightGBM] [Info] Start training from score -0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 151280, number of negative: 151280\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 302560, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best parameters: {'learning_rate': 0.1, 'min_child_samples': 30, 'n_estimators': 200, 'num_leaves': 50}\n",
      "[LightGBM] [Info] Number of positive: 151280, number of negative: 151280\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1303\n",
      "[LightGBM] [Info] Number of data points in the train set: 302560, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best LightGBM Model Accuracy: 0.7158962795941376\n",
      "Best LightGBM Model Precision: 0.23527864416970426\n",
      "Best LightGBM Model F1 Score: 0.3434260325818661\n",
      "Best LightGBM Model Recall: 0.6355699928941224\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_child_samples': [20, 30]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, scoring='f1', cv=3, verbose=1)\n",
    "grid_search.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train the best model\n",
    "best_lgb_model = grid_search.best_estimator_\n",
    "best_lgb_model.fit(X_train_ros, y_train_ros)\n",
    "y_pred = best_lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_accuracy = accuracy_score(y_test, y_pred)\n",
    "best_precision = precision_score(y_test, y_pred)\n",
    "best_f1 = f1_score(y_test, y_pred)\n",
    "best_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best LightGBM Model Accuracy: {best_accuracy}\")\n",
    "print(f\"Best LightGBM Model Precision: {best_precision}\")\n",
    "print(f\"Best LightGBM Model F1 Score: {best_f1}\")\n",
    "print(f\"Best LightGBM Model Recall: {best_recall}\")\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_lgb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('LightGBM Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "best_lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9b914bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['InterestRate','LoanAmount','Income','MonthsEmployed','CreditScore','Age','DTIRatio']\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_rus, y_rus = ros.fit_resample(X, y)\n",
    "X_rus=X_rus[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82de503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 225694, number of negative: 225694\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 451388, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(min_child_samples=30, n_estimators=200, num_leaves=50,\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_best_model=lgb.LGBMClassifier(min_child_samples=30,n_estimators=200,num_leaves=50,random_state=42)\n",
    "lgbm_best_model.fit(X_rus,y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52026763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InterestRate',\n",
       " 'LoanAmount',\n",
       " 'Income',\n",
       " 'MonthsEmployed',\n",
       " 'CreditScore',\n",
       " 'Age',\n",
       " 'DTIRatio']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_best_model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7968eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgbm_best_model.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model_filename = 'lgbm_best_model.pkl'\n",
    "joblib.dump(lgbm_best_model, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5999d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
